{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32629, 39)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use pandas to load data into a DataFrame\n",
    "# df = pd.read_csv(\"/home/danielbudi/Collage/comp-gammafest/comp-model/comp-dataset/mapped-v2_imputed_mf5iter.csv\")\n",
    "# df = pd.read_csv(\"/home/danielbudi/Collage/comp-gammafest/comp-model/comp-dataset/encode data/train.csv\")\n",
    "df = pd.read_csv(\"imputed_mf10iter_drop_outliers.csv\")\n",
    "df.shape # (rows, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_COLUMN = 'DC201'\n",
    "df_sampling = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_LIST = list(df.columns)\n",
    "NUMERICAL_DATA = ['DC216', 'DC220', 'DC142a']\n",
    "CATEGORICAL_DATA = [column for column in df.columns if column != TARGET_COLUMN and column not in NUMERICAL_DATA]\n",
    "\n",
    "COLUMN_CATEGORICAL_INDEX = []\n",
    "\n",
    "for column in CATEGORICAL_DATA:\n",
    "    COLUMN_CATEGORICAL_INDEX.append(df.columns.get_loc(column))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Feature and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = df[TARGET_COLUMN]\n",
    "# label = pd.DataFrame(label)\n",
    "df = df.drop(TARGET_COLUMN, axis=1)\n",
    "feature_df = df\n",
    "\n",
    "label_sampling = df_sampling[TARGET_COLUMN]\n",
    "# label = pd.DataFrame(label)\n",
    "df_sampling = df_sampling.drop(TARGET_COLUMN, axis=1)\n",
    "feature_sampling = df_sampling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "# from imblearn.over_sampling import SMOTENC\n",
    "\n",
    "# counter = Counter(label_sampling)\n",
    "# print(counter)\n",
    "\n",
    "# oversample = SMOTENC(sampling_strategy=0.2,\n",
    "#                      categorical_features=COLUMN_CATEGORICAL_INDEX,\n",
    "#                      random_state=42)\n",
    "# feature_sampling, label_sampling = oversample.fit_resample(feature_sampling, label_sampling)\n",
    "\n",
    "# counter = Counter(label_sampling)\n",
    "# print(counter)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non-SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from xgboost import XGBClassifier\n",
    "# from xgboost import plot_importance\n",
    "\n",
    "# # fit model no training data\n",
    "# model = XGBClassifier()\n",
    "# model.fit(feature_df, label_df)\n",
    "# # feature importance\n",
    "# print(model.feature_importances_)\n",
    "# # plot\n",
    "# fig, ax = plt.subplots(figsize=(10,10))\n",
    "# plot_importance(model, ax=ax)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.sort(feature_df['DC205'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_df_importance = feature_df[['DC024', 'DC142a', 'DC220', 'DC214', 'DC213', 'DC216',\n",
    "#                                     'DC205', 'DC235', 'DC270a', 'DC252', 'DC215', 'DC226', 'DC217']]\n",
    "# feature_df_importance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fit model no training data\n",
    "# model = XGBClassifier()\n",
    "# model.fit(feature_sampling, label_sampling)\n",
    "# # feature importance\n",
    "# print(model.feature_importances_)\n",
    "# # plot\n",
    "# fig, ax = plt.subplots(figsize=(10,10))\n",
    "# plot_importance(model, ax=ax)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.sort(feature_sampling['DC205'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_sampling.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_sampling_importance = feature_sampling[['DC024', 'DC142a', 'DC220', 'DC214', 'DC213', 'DC216', 'DC109',\n",
    "#                                                 'DC205', 'DC235', 'DC270a', 'DC252', 'DC215', 'DC226', 'DC230a']]\n",
    "# feature_sampling_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('../datasets/test.csv')\n",
    "test_id = test_df.pop('id')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# train set\n",
    "numerical_df_train = feature_sampling[NUMERICAL_DATA].astype(float).copy()\n",
    "categorical_df_train = feature_sampling[CATEGORICAL_DATA].astype('category').copy()\n",
    "\n",
    "# normalization\n",
    "scaler.fit(numerical_df_train)\n",
    "numerical_df_train = scaler.transform(numerical_df_train)\n",
    "numerical_df_train = pd.DataFrame(numerical_df_train, columns=NUMERICAL_DATA)\n",
    "\n",
    "\n",
    "# test set\n",
    "numerical_df_test = test_df[NUMERICAL_DATA].astype(float).copy()\n",
    "categorical_df_test = test_df[CATEGORICAL_DATA].astype('category').copy()\n",
    "\n",
    "# normalization\n",
    "numerical_df_test = scaler.transform(numerical_df_test)\n",
    "numerical_df_test = pd.DataFrame(numerical_df_test, columns=NUMERICAL_DATA)\n",
    "\n",
    "# Create an instance of the OneHotEncoder\n",
    "encoder = ce.OneHotEncoder(cols=CATEGORICAL_DATA, use_cat_names=True)\n",
    "\n",
    "# Fit the encoder on the training data\n",
    "encoder.fit(categorical_df_train)\n",
    "\n",
    "one_hot_df_train = encoder.transform(categorical_df_train)\n",
    "one_hot_df_test = encoder.transform(categorical_df_test)\n",
    "\n",
    "merged_df_train = pd.concat([numerical_df_train, one_hot_df_train], axis=1)\n",
    "merged_df_test = pd.concat([numerical_df_test, one_hot_df_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df_train\n",
    "# merged_df_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "TEST_SIZE = 0.2\n",
    "RANDOM_SEED = 42\n",
    "FOLD = StratifiedKFold(n_splits=3, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_train_norm, label_sampling, test_size=TEST_SIZE, random_state=RANDOM_SEED) # All Normalized\n",
    "X_train, X_test, y_train, y_test = train_test_split(merged_df_train, label_sampling, test_size = TEST_SIZE, random_state = RANDOM_SEED) # Numeric Normalized\n",
    "# X_train, X_test, y_train, y_test = train_test_split(feature_sampling, label_sampling, test_size=TEST_SIZE, random_state=RANDOM_SEED) # No Normalized\n",
    "# X_train, X_test, y_train, y_test = train_test_split(feature_df, label_df, test_size=TEST_SIZE, random_state=RANDOM_SEED) # No Normalized\n",
    "# X_train, X_test, y_train, y_test = feature_sampling, feature_df, label_sampling, label_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "# from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining parameter range\n",
    "# param_grid = {'learning_rate': [0.1, 0.01, 0.001],\n",
    "#               'min_child_weight':[1, 2, 3],\n",
    "#               'gamma':[0, 0.1, 0.001]}\n",
    "\n",
    "# grid = GridSearchCV(estimator=xgb,\n",
    "#                     param_grid=param_grid,\n",
    "#                     scoring='f1_micro', n_jobs=-1,\n",
    "#                     cv=FOLD, verbose=3)\n",
    "  \n",
    "# fitting the model for grid search\n",
    "# grid.fit(X_train, y_train) # Split the training and validation\n",
    "# grid.fit(X_train_norm, label) # All the training with normalized\n",
    "# grid.fit(X_resample, label) # All the training with numeric normalized\n",
    "# grid.fit(feature, label) # All the features no normalized\n",
    "\n",
    "# print(grid.best_params_)\n",
    "\n",
    "# grid_predictions = grid.best_estimator_.predict(X_test)\n",
    "# print(classification_report(y_test, grid_predictions, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.72691   0.26462   0.38800       684\n",
      "           1    0.91987   0.98836   0.95288      5842\n",
      "\n",
      "    accuracy                        0.91250      6526\n",
      "   macro avg    0.82339   0.62649   0.67044      6526\n",
      "weighted avg    0.89964   0.91250   0.89368      6526\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lgbm = LGBMClassifier(boosting_type='dart', n_estimators=1000, subsample=0.8,\n",
    "                      colsample_bytree=0.8, scale_pos_weight=2, num_leaves=100,\n",
    "                      random_state=42, learning_rate=0.1, min_child_weight=2, max_depth=22)\n",
    "lgbm.fit(X_train, y_train)\n",
    "\n",
    "prediction = lgbm.predict(X_test)\n",
    "print(classification_report(y_test, prediction, digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Threshold\n",
    "\n",
    "# from sklearn.metrics import f1_score\n",
    "\n",
    "# # Make probability predictions on the validation data\n",
    "# y_prob = lgbm.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# # Compute the F1 score for different threshold values\n",
    "# thresholds = np.arange(0, 1.01, 0.01)\n",
    "# f1_scores = [f1_score(y_test, y_prob > t) for t in thresholds]\n",
    "\n",
    "# # Find the threshold that gives the highest F1 score\n",
    "# best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "# best_f1_score = np.max(f1_scores)\n",
    "\n",
    "# print(f'Best threshold: {best_threshold}')\n",
    "# print(f'Best F1 score: {best_f1_score}')\n",
    "\n",
    "# # Make binary predictions using the best decision threshold\n",
    "# y_pred = y_prob > best_threshold\n",
    "\n",
    "# print(classification_report(y_test,y_pred, digits=4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grid_predictions = grid.best_estimator_.predict(test_norm)\n",
    "# grid_predictions = grid.best_estimator_.predict(test_df1)\n",
    "# grid_predictions = xgb.predict(test_norm)\n",
    "grid_predictions = lgbm.predict(merged_df_test)\n",
    "# grid_predictions = model.predict(test_copy)\n",
    "grid_predictions[-100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Threshold\n",
    "\n",
    "# P_prod_submit = lgbm.predict_proba(test_norm)[:, 1] > best_threshold\n",
    "# P_prod_submit = grid.best_estimator_.predict(X_test_submit)\n",
    "# P_prod_submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>DC201</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26718</td>\n",
       "      <td>Layak Minum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26802</td>\n",
       "      <td>Layak Minum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41302</td>\n",
       "      <td>Layak Minum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38698</td>\n",
       "      <td>Layak Minum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44257</td>\n",
       "      <td>Layak Minum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11985</th>\n",
       "      <td>36943</td>\n",
       "      <td>Layak Minum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11986</th>\n",
       "      <td>33415</td>\n",
       "      <td>Layak Minum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11987</th>\n",
       "      <td>41998</td>\n",
       "      <td>Layak Minum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11988</th>\n",
       "      <td>41567</td>\n",
       "      <td>Layak Minum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11989</th>\n",
       "      <td>45296</td>\n",
       "      <td>Layak Minum</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11990 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id        DC201\n",
       "0      26718  Layak Minum\n",
       "1      26802  Layak Minum\n",
       "2      41302  Layak Minum\n",
       "3      38698  Layak Minum\n",
       "4      44257  Layak Minum\n",
       "...      ...          ...\n",
       "11985  36943  Layak Minum\n",
       "11986  33415  Layak Minum\n",
       "11987  41998  Layak Minum\n",
       "11988  41567  Layak Minum\n",
       "11989  45296  Layak Minum\n",
       "\n",
       "[11990 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "for res in grid_predictions:\n",
    "# for res in P_prod_submit:\n",
    "  result.append('Layak Minum' if res==1 else 'Tidak Layak Minum')\n",
    "\n",
    "finish_pd = pd.DataFrame({'id':test_id.values, 'DC201':result})\n",
    "finish_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DC201\n",
       "Layak Minum          11553\n",
       "Tidak Layak Minum      437\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finish_pd['DC201'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finish_pd.to_csv('/home/danielbudi/Collage/comp-gammafest/comp-model/comp-dataset/result-file/result-LGBM-one_hot_encode-no_SMOTE-MinMax-Cat_modus_num_imputation.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
